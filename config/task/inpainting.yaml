# model:
#   base_learning_rate: 1.0e-06
#   target: ldm.models.diffusion.ddpm.LatentDiffusion
#   params:
#     linear_start: 0.0015
#     linear_end: 0.0205
#     log_every_t: 100
#     timesteps: 1000
#     loss_type: l1
#     first_stage_key: image
#     cond_stage_key: masked_image
#     image_size: 64
#     channels: 3
#     concat_mode: true
#     monitor: val/loss
#     scheduler_config:
#       target: ldm.lr_scheduler.LambdaWarmUpCosineScheduler
#       params:
#         verbosity_interval: 0
#         warm_up_steps: 1000
#         max_decay_steps: 50000
#         lr_start: 0.001
#         lr_max: 0.1
#         lr_min: 0.0001

diffusion: edm
model:
  image_size: 64
  in_channels: 7
  out_channels: 3
  model_channels: 256
  attention_resolutions:
  - 8
  - 4
  - 2
  num_res_blocks: 2
  channel_mult:
  - 1
  - 2
  - 3
  - 4
  num_heads: 8
  resblock_updown: true

trainer:
  constructor:
    lr: 1.e-3
    output_dir: ./trainer_output
    exp_name: inpainting_edm
    distributed: False

  train_method:
    batch_size: 32
    batch_size_per_device: 16
    max_steps: 100000
    num_epochs: null
    resume_training: False
    chkpt_save_steps: 10000  
    train_log_steps: 1000 
    eval_log_steps: 2000 

